# Automatically generated by Pynguin.
import typesystem.tokenize.tokenize_json as module_0

def test_case_0():
    pass

def test_case_1():
    str_0 = '{"name":"John",\n    "age":30,\n    "cars": [\n        {"name":"Ford", "models":[ "Fiesta", "Focus", "Mustang" ]},\n        {"name":"BMW", "models":[ "320", "X3", "X5" ]},\n        {"name":"Fiat", "models":[ "500", "Panda" ]}\n    ]\n}'
    token_0 = module_0.tokenize_json(str_0)

def test_case_2():
    str_0 = '{"string_key": "string_value", "int_key": 10, "float_key": 3.14, "null_key": null, "true_key": true, "false_key": false}'
    token_0 = module_0.tokenize_json(str_0)

def test_case_3():
    str_0 = '\n    {\n        "a": [1, 2, 3],\n        "b": "hello",\n        "c": true,\n        "d": null,\n        "e": {\n            "f": 1.2,\n            "g": 1.2e2\n       }\n    }\n    '
    token_0 = module_0.tokenize_json(str_0)