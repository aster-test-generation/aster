# Automatically generated by Pynguin.
import typesystem.tokenize.tokenize_json as module_0

def test_case_0():
    pass

def test_case_1():
    str_0 = '{"first_name": "Guido", "last_name":"Rossum"}'
    token_0 = module_0.tokenize_json(str_0)

def test_case_2():
    bytes_0 = b'\n        {\n            "field1": "value1",\n            "field2": 2,\n            "field3": 3.4,\n            "field4": [1, "a", 3.3],\n            "field5": {\n                "field6": null,\n                "field7": "value7",\n                "field8": 8\n            },\n            "field9": [9, "b", 3.3]\n        }\n    '
    token_0 = module_0.tokenize_json(bytes_0)

def test_case_3():
    str_0 = '\n        [\n            {"name": "John Doe", "year_of_birth": 1954},\n            {"name": "Jane Doe", "year_of_birth": 1982},\n            {"name": "Santa Claus", "year_of_birth": 1908}\n        ]\n    '
    token_0 = module_0.tokenize_json(str_0)

def test_case_4():
    str_0 = '{\n        "name": "John",\n        "age": 30,\n        "cars": {\n            "car1": "Ford",\n            "car2": "BMW",\n            "car3": "Fiat"\n        }\n    }'
    token_0 = module_0.tokenize_json(str_0)

def test_case_5():
    str_0 = 'false'
    token_0 = module_0.tokenize_json(str_0)
    token_1 = module_0.tokenize_json(str_0)

def test_case_6():
    str_0 = '{\n     "foo": "bar",\n     "cool": true,\n     "age": 25,\n     "friends": ["John", "Jane"],\n     "address": {\n         "street": "Main Street",\n         "number": 123\n     }\n }'
    token_0 = module_0.tokenize_json(str_0)

def test_case_7():
    str_0 = '{"name" : "Jim", "age": "24", "survived": "Yes"}'
    token_0 = module_0.tokenize_json(str_0)
    var_0 = token_0.value
    var_1 = len(var_0)
    str_1 = '["10", "Hello", "100"]'
    token_1 = module_0.tokenize_json(str_1)
    var_2 = token_1.value
    var_3 = len(var_2)

def test_case_8():
    str_0 = '[]'
    token_0 = module_0.tokenize_json(str_0)
    str_1 = '{}'
    token_1 = module_0.tokenize_json(str_1)
    token_2 = module_0.tokenize_json(str_0)